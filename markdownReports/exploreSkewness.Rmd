---
title: "Skewed Distribution Adjustments"
author: "Cam Freshwater"
date: "February 7, 2019"
output: html_document
---

First some context. Sean Anderson demonstrated that the mean is negatively correlated with the strength of covariance in skewed distributions. First extend his initial investigation to evaluate variance, covariance, and skewness interact to drive changes in mean.

```{r changesInProd}
require(tidyverse); require(ggplot2)

f <- function(N = 15, r = 0.4, sigma = 0.2, skew = 0.65) {
  sig_mat <- matrix(as.numeric(sigma), nrow = 1, ncol = N)
  cov_mat <- (t(sig_mat) %*% sig_mat) * r
  diag(cov_mat) <- sigma^2
  x <- sn::rmst(1e5, xi = rep(0, N), Omega = cov_mat,
    alpha = rep(log(skew), N), nu = 200)
  as.numeric(x)
}

x <- f(2)
mean(x)

.r <- seq(0, 0.7, 0.05)
.skew <- seq(0.5, 1, by = 0.05)
yListSkew <- lapply(seq_along(.skew), function (i) {
  purrr::map_df(.r, ~ data.frame(mean = mean(f(r = .x,
                                               skew = .skew[i])))) %>% 
    dplyr::mutate(skewness = .skew[i],
           correlation = .r)
})

plotDat <- do.call(rbind, yListSkew) %>% 
  dplyr::mutate(skewness = round(skewness, digits = 3))

ggplot(plotDat, aes(correlation, mean, colour = as.factor(skewness))) +
  geom_line() +
  samSim::theme_sleekX()

.sigma <- seq(0.05, 0.75, 0.05)
yListSig <- lapply(seq_along(.sigma), function (i) {
  purrr::map_df(.r, ~ data.frame(mean = mean(f(r = .x,
                                               sigma = .sigma[i])))) %>% 
    dplyr::mutate(sigma = .sigma[i],
                  correlation = .r)
})

plotDatSig <- do.call(rbind, yListSig)
ggplot(plotDatSig, aes(correlation, mean, colour = as.factor(sigma))) +
  geom_line() +
  samSim::theme_sleekX()

```

First plot shows that it really doesn't take much skewness to trigger that relationship, but increasing the skewness dramatically doesn't really alter the slope of that relationship too much.

Second plot shows sigma's impact on mean productivity. 

-----

#### Compare reference, Kalman A and various skewness-based operating models

Next look at whether an alternative skewed distribution OM could be presented to contrast with standard low alpha results. Methods would clearly note that low a represents declines in productivity that are concurrent, but not synchronized at annual level, while skewed declines are directly influenced by strength of covariance.

Parameterization is a little ambiguous, but one option is to take a reference covariance matrix and tune the skewness parameter to produce declines in CU-specific productivity that approximate those of kalman alpha. Then use the mean skewness parameter among stocks to forward simulate. Reference covariance matrix could be either the reference sigma and moderate correlation matrix **or** the covariance matrix calculated from mean correlations among CUs. Option 1 would result in synch treatments that are identical to what we have now and would be easier to implement. Option 2 may make the most sense if we used scalars to drive CU-specific patterns of covariance up/down. This may be more accurate, but since the trends will be CU-specific I'm not sure if it's more or less broadly applicable.

First step is to calculate the two covariance matrices. Also calculate a third equivalent to option 1, but with stronger correlation just to see what patterns result.

```{r loadData}
require(here); require(samSim); require(tidyverse)

#Focus only on Ricker stocks because Larkin aren't amenable to easy
#comparisons of realized recruitment. 
cuPars <- read.csv(here("data", "sox", "fraserCUPars.csv")) %>% 
  filter(model == "ricker")
residMat <- readRDS(here("outputs", "generatedData", 
                         "residMat.rds"))[ , as.character(cuPars$stk)]
srDat <- read.csv(here("data", "sox", "fraserRecDatTrim.csv")) %>% 
  filter(stk %in% cuPars$stk)

nStks <- length(unique(cuPars$stkName))
alphas <- cuPars$alpha
betas <- cuPars$beta0
sigmas <- cuPars$sigma

## Covariance matrix 1 (based on sigmas and arbitrary correlation coef)
r <- 0.5 #default moderate correlation
sigMat <- matrix(as.numeric(sigmas), nrow = 1, ncol = nStks)
covMat1 <- (t(sigMat) %*% sigMat) * r
diag(covMat1) <- sigmas^2

## Covariance matrix 2 (based on residuals)
calcCorMat <- function(mat) {
  N <- ncol(mat)
  corMat <- matrix(NA, nrow = N, ncol = N)
  for (i in 1:N) {
    for (j in 1:N) {
      dum <- cbind(mat[ , i], mat[ , j])
      dum <- dum[complete.cases(dum), ]
      corMat[j, i] <- cor(dum)[2,1]
    }
  }
  return(corMat)
}

## Generate covariance based on residuals from simple lm
corMat <- calcCorMat(residMat)
sigMat <- matrix(as.numeric(sigmas), nrow = 1, ncol = nStks)
covMat2 <- (t(sigMat) %*% sigMat) * corMat
diag(covMat2) <- sigmas^2

## Covariance matrix 3 (based on sigmas and high correlation coef)
sigMat <- matrix(as.numeric(sigmas), nrow = 1, ncol = nStks)
covMatHigh <- (t(sigMat) %*% sigMat) * 0.75
diag(covMatHigh) <- sigmas^2
```

Next generate estimates of recruitment (outside of a closed-loop) using a Ricker model and four productivity operating models

1.  Reference - median alpha estimate + log MVN error from default covariance matrix
2.  Low alpha - median alpha with 0.65 scalar (mean difference between min Kalman estimate and median) + log MVN error from default covariance matrix
3.  Skewed default - median alpha + skewed MVN error (skewness parameters ranging from log(0.65) to log(0.95)) with default covariance matrix
4.  Skewed custom - median alpha + skewed MVN error (as above) with CU-specific covariance
5.  Skewed high - median alpha + skewed MVN error (as above) with highly correlated covariance matrix

```{r calcRealizedRecruitment}
N = 1000
meanS <- srDat %>% 
  group_by(stk) %>% 
  summarize(meanS = mean(totalSpwn, na.rm = TRUE)) %>% 
  select(meanS) %>%
  unlist() %>% 
  as.numeric()

simpleRicker <- function(S, a, b, error) {
    S * exp(a - b * S) * exp(error)
}

#Generate estimates of recruitment based on low productivity parameters
ricSim <- function(N, meanS, alphas, betas, covMat, covMatName, stkNames, 
                   normal = TRUE, skewPar) {
  nStks <- length(stkNames)
  trialSeq <- seq(1, N, by = 1)
  outList <- lapply(1:N, function (x) {
   if (normal == TRUE) {
    err <- sn::rmst(n = 1, xi = rep(0, nStks), Omega = covMat, 
                    alpha = rep(0, nStks), nu = 1000) %>% 
      as.numeric()
  }
  if (normal == FALSE) {
    err <- sn::rmst(n = 1, xi = rep(0, nStks), Omega = covMat, 
                    alpha = rep(log(skewPar), nStks), nu = 1000) %>% 
      as.numeric()
  }
  data.frame(trial = trialSeq[x],
             skew = as.factor(skewPar),
             covMat = covMatName,
             CU = stkNames,
             rec = simpleRicker(meanS, alphas, betas, error = err)) 
  })
  outDat <- do.call(rbind, outList) %>% 
    mutate(skew = as.factor(skew))
  return(outDat)
}

## Assume that low Kalman A is 0.65 current estimate
lowAlphas <- 0.65 * alphas
outNorm <- ricSim(N, meanS, alphas, betas, covMat = covMat1, 
                  covMatName = "default", stkNames = cuPars$stkName, 
                  normal = TRUE, skewPar = "ref")
outLow <- ricSim(N, meanS, lowAlphas, betas, covMat = covMat1, 
                  covMatName = "default", stkNames = cuPars$stkName, 
                  normal = TRUE, skewPar = "lowA")
skewPars <- seq(0.4, 0.9, by = 0.1)
outSkewList1 <- lapply(seq_along(skewPars), function (h) {
  ricSim(N, meanS, alphas, betas, covMat = covMat1, covMatName = "default", 
         stkNames = cuPars$stkName, normal = FALSE, skewPar = skewPars[h])
})
outSkewList2 <- lapply(seq_along(skewPars), function (h) {
  ricSim(N, meanS, alphas, betas, covMat = covMat2, covMatName = "custom", 
         stkNames = cuPars$stkName, normal = FALSE, skewPar = skewPars[h])
})
outSkewList3 <- lapply(seq_along(skewPars), function (h) {
  ricSim(N, meanS, alphas, betas, covMat = covMatHigh, covMatName = "high", 
         stkNames = cuPars$stkName, normal = FALSE, skewPar = skewPars[h])
})
outDat <- rbind(outNorm, outLow, do.call(rbind, outSkewList1), 
                 do.call(rbind, outSkewList2), do.call(rbind, outSkewList3))
```

First look at differences between different skewed covariance matrices.

``` {r plotDifferentSkewed}
stks <- unique(c(sample.int(length(cuPars$stkName), size = 3, replace = FALSE), 
                 13))

for (i in seq_along(stks)) {
  dum <- outDat %>% 
    filter(CU == cuPars$stkName[i],
           !skew %in% c("ref", "lowA"))
  p <- ggplot(dum, aes(x = skew, y = rec)) +
    geom_boxplot() +
    theme_sleekX() +
    ggtitle(cuPars$stkName[i]) +
    facet_wrap(~covMat)
  print(p)
}

outDat %>% 
  filter(!skew %in% c("ref", "lowA")) %>% 
  group_by(CU, covMat , skew)
```

Overall outcomes are quite similar between default and custom except for Harrison. This isn't entirely unexpected given that there is strong coherence within the aggregate, except for this sea-type stock. High covariance leads to a shift downwards.

Next compare the multivariate normal distributions to the skewed with custom covariance matrix (default results were qualitatively similar; subset of stocks shown).
``` {r compareSkewedMVN}
colPal <- c("#ffeda0", "#feb24c", rep("#f03b20", length.out = length(skewPars))) 
names(colPal) <- levels(outDat$skew)

stkSample <- unique(sample.int(length(cuPars$stkName), size = 6, replace = FALSE))
stks <- cuPars$stkName[stkSample]

plotDat1 <- outDat %>% 
  filter(skew %in% c("ref", "lowA") | covMat == "custom",
         CU %in% stks)

ggplot(plotDat1, aes(x = skew, y = rec, fill = skew)) +
  geom_boxplot() +
  theme_sleekX(axisSize = 9, legendSize = 0.8) +
  scale_fill_manual(name = "Skewness", values = colPal) +
  facet_wrap(~CU, scales = "free_y")
```

Varies among CUs, but generally low alpha produces recruit abundances smaller than even  severe skewness parameters. 

What happens when we use a relatively extreme covariance matrix (r = 0.75).

``` {r plotHighCovComparison}
plotDat2 <- outDat %>% 
  filter(skew %in% c("ref", "lowA") | covMat == "high",
         CU %in% stks)

ggplot(plotDat2, aes(x = skew, y = rec, fill = skew)) +
  geom_boxplot() +
  theme_sleekX(axisSize = 9, legendSize = 0.8) +
  scale_fill_manual(name = "Skewness", values = colPal) +
  facet_wrap(~CU, scales = "free_y")
```

Depending on CUs even high skewness and high covariance doesn't result in realized productivity patterns that are more severe than Kalman filter estimates. However ultimately the issue is do trends in CU-specific PMs make sense across synchrony treatments within a given productivity OM.

Plot again to refresh:

``` {r lookAtCUSpecificPMs}
simPar <- read.csv(here("data/sox/fraserOMInputs_varyCorr.csv"), 
                   stringsAsFactors = F)

simParTrim <- subset(simPar, scenario %in% c("medSig", "medSigSkew",
                                             "medSigLowA"))
scenNames <- unique(simParTrim$scenario)
dirNames <- sapply(scenNames, function(x) paste(x, unique(simParTrim$species),
                                                sep = "_"))

omNames <- c("ref", "skewN", "lowA")

fullPlotList <- list()
for (i in seq_along(omNames)) { #make dataframe
  cuList <- genOutputList(dirNames[i], agg = FALSE)
  plotList <- lapply(cuList, function(h) {
    plotDat <- NULL
    sMat <- h[["medSpawners"]]
    nCUs <- length(h[["stkName"]])
    stkNames <- h[["stkName"]]
    colnames(sMat) <- stkNames
    nTrials <- nrow(sMat)
    sDat <- data.frame(om = rep(omNames[i], length.out = nTrials * nCUs),
                          synch = rep(unique(h[["opMod"]]), 
                                      length.out = nTrials * nCUs)
    )
    dum <- sMat %>%
      as.data.frame() %>%
      gather(key = cu, value = spwn)
    plotDat <- rbind(plotDat, cbind(sDat, dum))
    return(plotDat)
  })
  plotDat2 <- do.call(rbind, plotList)
  fullPlotList[[paste0(omNames[i])]] <- plotDat2
}

plotDatFull <- do.call(rbind, fullPlotList) %>% 
  mutate(cu = as.factor(cu),
         synch = factor(synch, levels = c("lowSynch", "medSynch", 
                                          "highSynch"))) %>% 
  filter(cu %in% c("Chlk", "Clts", "L.Sh", "Hrrs"))

lineSize = 0.8; legSize = 0.7; axSize = 10; facetSize = 0.95
ggplot(plotDatFull, aes(x = om, y = spwn, alpha = synch)) +
  geom_boxplot() +
  scale_alpha_manual(name = "Synchrony", values = c(1, 0.65, 0.3),
                     labels = c("low" = "Low",
                                "med" = "Ref.",
                                "high" = "High")) +
  guides(alpha = guide_legend(override.aes = list(fill = "grey30"))) +
  labs(y = "Median Spawner Abundance (millions)",
       x = "Productivity Scenario") +
  theme_sleekX(facetSize = 1.1, axisSize = axSize - 1, 
               legendSize = legSize * 0.75) +
  facet_wrap(~cu, scales = "free_y", nrow = 2)

```

Note that while skewed normal distributions do result in strong declines in median spawner abundance as synchrony increases (the original red flag), MVN distributions exhibit an opposite, though weaker, pattern. Revisit the simulations, this time generating recruits from MVN w/ high covariance matrix.

```{r simHighCovar}
outNorm <- ricSim(N*10, meanS, alphas, betas, covMat = covMat1, 
                  covMatName = "default", stkNames = cuPars$stkName, 
                  normal = TRUE, skewPar = "ref")
outNormHigh <- ricSim(N*10, meanS, alphas, betas, covMat = covMatHigh, 
                  covMatName = "high", stkNames = cuPars$stkName, 
                  normal = TRUE, skewPar = "ref")
# skewPars <- seq(0.4, 0.9, by = 0.1)
# outSkewList1 <- lapply(seq_along(skewPars), function (h) {
#   set.seed(123)
#   ricSim(N, meanS, alphas, betas, covMat = covMat1, covMatName = "default", 
#          stkNames = cuPars$stkName, normal = FALSE, skewPar = skewPars[h])
# })
# outSkewList2 <- lapply(seq_along(skewPars), function (h) {
#   set.seed(123)
#   ricSim(N, meanS, alphas, betas, covMat = covMat2, covMatName = "custom", 
#          stkNames = cuPars$stkName, normal = FALSE, skewPar = skewPars[h])
# })
# outSkewList3 <- lapply(seq_along(skewPars), function (h) {
#   set.seed(123)
#   ricSim(N, meanS, alphas, betas, covMat = covMatHigh, covMatName = "high", 
#          stkNames = cuPars$stkName, normal = FALSE, skewPar = skewPars[h])
# })
outDat <- rbind(outNorm, outNormHigh)

ggplot(outDat %>% filter(!CU == "Cultus"), aes(x = covMat, y = rec)) +
  geom_boxplot() +
  theme_sleekX() +
  facet_wrap(~CU, scales = "free_y")

summDat1 <- outDat %>% 
  group_by(CU, covMat) %>% 
  summarize(meanRec = mean(rec),
            medRec = median(rec))
print(summDat1)
```

Differences disappear with simpler simulations. Perhaps they are a function of harvest (which drives up ppn above the benchmark). Examine synchAndPpnPMs.Rmd