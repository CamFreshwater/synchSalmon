---
title: "Productivity Scenarios"
author: "Cam Freshwater"
date: "October 10, 2018"
output: html_document
---

```{r, warning=FALSE, message=FALSE, echo = FALSE}
library(sn); library(tidyverse); library(here); library(ggpubr); require(synchrony);
library(zoo); library(reshape2); library(viridis); library(samSim)
```


The broad goal of this document is to get a better handle on what exactly the different productivity operating models (OMs) are doing in terms of driving changes in productivity (log R/S) and recruit abundance. We'll start by looking at the distributions themselves, then move to incorporating them into the closed loop model. 

First compare the three distributions in a univariate context. Alpha represents skewness parameter (in the sn pacakge 0 is symmetrical, we use log space to be consistent w/ S. Anderson's manuscript) and nu represents the heavy tailed distribution (anything >10 approaches normal). Remember we are using log(0.65) because that is a value marginally more pessimistic than the mean skewness parameter estimated from Fraser CU-specific stock-recruit models (i.e. Ricker or Larkin models that estimate additional skewness parameters).

```{r generate distributions}
n = 1000000
mu = 0
sig = 1
norm <- rst(n, xi = mu, omega = sig, alpha = log(1), nu = Inf)
skewNorm <- rst(n, xi = mu, omega = sig, alpha = log(0.65), nu = Inf)
skewT <- rst(n, xi = mu, omega = sig, alpha = log(0.65), nu = 3)

distDat <- cbind(norm, skewNorm, skewT) %>% 
  as.data.frame() %>% 
  gather(key = dist, value = value) %>% 
  mutate(dist = as.factor(dist))
```

```{r calculate medians and generate violin plots, echo = FALSE}
distDat %>% 
  group_by(dist) %>% 
  summarize(median = median(value), mean = mean(value), sd = sd(value))

ggplot(distDat, aes(x = dist, y = value)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  geom_hline(yintercept = 0, linetype = 2, size = 2) + 
  ylim(-5, 5)
```

So skewed distributions shift the median and mean, which makes sense - otherwise there would be no effect on productivity! Note also that while variance is similar for normal and skewed normal, it is substantially larger for skewed t.

To get an idea of what this means for estimates of recruitment simply plug residual variance values into a Ricker model parameterized with median values for Chilko (which is used as an example in subsequent figures). Note that the low A value is the 5th percentile of the posterior estimate of alpha (courtesy of AMH)

```{r generate estimates of recruitment}
chlkA = 1.8315
chlkLowA = 1.58795
chlkB = 1.23182
meanChlkS = 0.3792771
chlkSig = 0.79075
recCap = 14.4 #cap on maximum recruitment

#Generate estimates of recruitment based on Chilko parameters and different
#deviation distributions
normRec <- rickerModel(meanChlkS, chlkA, chlkB, 
                       error = rst(n, xi = 0, omega = chlkSig, alpha = log(1), 
                                   nu = Inf), 
                       rho = 0, utminus = 0)[[1]]
normLowARec <- rickerModel(meanChlkS, chlkLowA, chlkB, 
                       error = rst(n, xi = 0, omega = chlkSig, alpha = log(1), 
                                   nu = Inf), 
                       rho = 0, utminus = 0)[[1]]
skewNormRec <- rickerModel(meanChlkS, chlkA, chlkB, 
                       error = rst(n, xi = 0, omega = chlkSig, alpha = log(0.65), 
                                   nu = Inf), 
                       rho = 0, utminus = 0)[[1]]
skewTRec <- rickerModel(meanChlkS, chlkA, chlkB, 
                       error = rst(n, xi = 0, omega = chlkSig, alpha = log(0.65), 
                                   nu = 3), 
                       rho = 0, utminus = 0)[[1]]

recDat <- cbind(normRec, normLowARec, skewNormRec, skewTRec) %>% 
  as.data.frame() %>% 
  gather(key = prodOM, value = recruits) %>% 
  mutate(prodOM = as.factor(prodOM)) %>% 
  mutate(prodOM = factor(prodOM, levels(prodOM)[c(2, 1, 3, 4)])) %>% 
  filter(recruits < recCap) #remove absurdly large positive recruitment events

ggplot(recDat, aes(x = prodOM, y = recruits)) +
  geom_boxplot()
```

So for any given independent recruitment event there isn't a strong distribution effect (i.e. median recruitment is about the same across lowA, skewN and skewT operating models). However, obviously this changes in a closed loop simulation context where feedbacks occur.


Next step is to read in data from a simulation run w/ the four different prod regimes and see what the effects on PMs look like. Note that this particular run is light on trials (n = 25), resulting in some messy trends but the overall patterns are approximately the same when n is bumped up to 500 or 1000.

```{r retrieve data for PMs plot, echo = FALSE, warning = FALSE}
simPar <- read.csv(here("data/simRunInputs/fraserOMInputs_varyCorr.csv"), stringsAsFactors = F)
simParTrim <- subset(simPar, 
                     scenario == "lowSig" | scenario == "medSig" | 
                       scenario == "highSig" | scenario == "lowSigLowA" | 
                       scenario == "medSigLowA" | scenario == "highSigLowA" | 
                       scenario == "lowSigSkew" | scenario == "medSigSkew" | 
                       scenario == "highSigSkew" | scenario == "lowSigSkewT" |
                       scenario == "medSigSkewT" | scenario == "highSigSkewT"
                     )
scenNames <- unique(simParTrim$scenario)
dirNames <- sapply(scenNames, function(x) paste(x, unique(simParTrim$species), sep = "_"))

vars <- c("medRecRY", "ppnCUUpper", "ppnCUExtant",
          "medCatch", "ppnYrsHighCatch", "stabilityCatch")
omNames <- rep(c("ref", "skewN", "skewT", "lowA"), each = 3)
sigNames <- rep(c("low", "med", "high"), length.out = 12)

plotDat = NULL
for(h in seq_along(dirNames)) {
  agList <- genOutputList(dirNames[h], agg = TRUE)
  keyVar <- sapply(agList, function(x) unique(x$keyVar))
  plotOrder <- sapply(agList, function(x) unique(x$plotOrder))
  singleScen = NULL
  for (i in seq_along(vars)) {
    dum <- data.frame(sigma = rep(sigNames[h], length.out = length(agList)),
                      om = rep(omNames[h], length.out = length(agList)),
                      var = rep(vars[i], length.out = length(agList)),
                      synch = as.factor(keyVar),
                      cat = as.factor(plotOrder),
                      avg = sapply(agList, function(x) median(x[,vars[i]])),
                      lowQ = sapply(agList, function(x) qLow(x[,vars[i]])),
                      highQ = sapply(agList, function(x) qHigh(x[,vars[i]])),
                      row.names = NULL
    )
    singleScen <- rbind(singleScen, dum)
  }
  rownames(singleScen) <- c()
  plotDat <- rbind(plotDat, singleScen) #merge multiple scenarios into one dataframe
}
plotDat <- plotDat %>% 
  mutate(cat = recode(cat, "1" = "low", "2" = "med", "3" = "high", 
                      .default = levels(cat)),
         om = recode(om, "ref" = "Reference", "lowA" = "Low Alpha", 
                     "skewN" = "Skewed Normal", "skewT" = "Skewed T",
                     .default = levels(om))
  ) %>% 
  mutate(om = factor(om, levels(om)[c(1,4,2,3)]))

colPal <- viridis(length(levels(plotDat$sigma)), begin = 0, end = 1)
names(colPal) <- levels(plotDat$sigma)
axisSize = 14; dotSize = 3.5; lineSize = 0.8

consVars <- c("medRecRY", "ppnCUUpper", "ppnCUExtant") 
consYLabs <- c("Recruit\nAbundance", "Prop. CUs Above\nUpper BM", 
               "Prop. CUs\nExtant")
consPlots <- lapply(seq_along(consVars), function(i) {
  temp <- plotDat %>% 
    filter(var == consVars[i])
  q <- ggplot(temp, aes(x = sigma, y = avg, ymin = lowQ, ymax = highQ, 
                        color = cat, shape = sigma)) +
    labs(x = "Component Variance", y = consYLabs[i], 
         color = "Sim.\nParameter\nValue") +
    geom_pointrange(fatten = dotSize, size = lineSize, 
                    position = position_dodge(width = 0.5)) +
    scale_x_discrete(labels = c("low" = expression(paste("0.5", sigma)),
                                "med" = expression(paste("1.0", sigma)),
                                "high" = expression(paste("1.5", sigma)))) +
    scale_colour_manual(name = "Synchrony", values = colPal,
                        labels = c("low" = expression(paste(rho, " = 0.05")),
                                   "med" = expression(paste(rho, " = 0.50")),
                                   "high" = expression(paste(rho, " = 0.75")))) +
    scale_shape_manual(name = "Sigma", breaks = c("low", "med", "high"), 
                       values = c(16, 17, 18), guide = FALSE) +
    facet_wrap(~om, scales = "fixed", ncol = 4)
  if (i == 1) {
    q <- q + theme_sleekX(position = "top", legendSize = 1.05)
  } 
  if (i == 2) {
    q <- q + theme_sleekX(position = "mid", legendSize = 1.05)
  }
  if (i == 3) {
    q <- q + theme_sleekX(position = "bottom", legendSize = 1.05)
  }
  return(q)
})
ggarrange(consPlots[[1]], consPlots[[2]], consPlots[[3]], 
          ncol = 1, nrow = 3, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1.1,1,1.2))
```

Similar effects among low A, skewN and skewT at low levels of synchrony, but interactions between synchrony and recruitment deviations result in stronger declines among the skewed OMs when synchrony is bumped to moderate or high values. In other words, the effect of synchrony is greater when declines in overall productivity are driven by changes in sigma rather than alpha **even though** mean abundance across a large number of independent events is the same across OMs.


To determine what is driving this outcome look at individual trials to assess how realized productivity varies across OMs. Look at single trial first, using only data from medium synchrony, medium component variability treatments, focusing on Chilko.

```{r plot temporal trends in realized productivity and distribution, echo=FALSE, warning=FALSE}
arrayNames <- sapply(dirNames[1], function(x) { #matrix of array names to be passed
  list.files(paste(here("outputs/simData"), x, sep="/"), pattern = "\\Arrays.RData$")
})
sigNames <- rep(c("lowSig", "medSig", "highSig"), length.out = 12)
omNames <- rep(c("ref", "skewN", "skewT", "lowA"), each = 3)

prodList <- lapply(seq_along(dirNames), function(h) { 
  #medSynch treatment only
  datList <- readRDS(paste(here("outputs/simData"), dirNames[h], arrayNames[3], sep = "/"))
  prodDat <- datList$recBY %>% 
    melt() %>% 
    rename("yr" = "Var1", "cu" =  "Var2", "trial" = "Var3", "var" = "value") %>% 
    mutate(sig = sigNames[h], om = omNames[h])  
  return(prodDat)
}) 

prodFull <- do.call(rbind, prodList) %>% 
  filter(sig == "medSig", !yr < 60) %>% #focus on median sig treatment, sim period
  mutate(om = as.factor(om)) %>% 
  mutate(om = factor(om, levels(om)[c(2,1,3,4)]))
drawTrials <- sample.int(max(prodFull$trial), size = 4, replace = FALSE)

plotList <- lapply(seq_along(drawTrials), function(i) { 
  dum <- prodFull %>% 
    #focus on Chilko data only
    filter(trial == drawTrials[i] , cu == 7) 
  q <- ggplot(dum, aes(x = yr, y = var, colour = om)) +
    labs(x = "Year", y = "", title = drawTrials[i]) +
    geom_line(size = 1) +
    scale_colour_discrete(name = "Operating Model") +
    theme_sleekX(position = "bottom") +
    theme(axis.title.y=element_blank()) +
    facet_wrap(~om, nrow = length(unique(omNames)), ncol = 1)
  p <- ggplot(dum, aes(x = om, y = var, fill = om)) +
    geom_boxplot() +
    labs(x = "Op Model", y = "", title = drawTrials[i]) +
    theme_sleekX(position = "bottom") +
    theme(axis.title.y = element_blank(), axis.title.x = element_blank())
  return(list(q, p))
})

prodLine <- ggarrange(plotList[[1]][[1]], plotList[[2]][[1]],
          plotList[[3]][[1]], plotList[[4]][[1]], 
          ncol = 4, nrow = 1, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1.1,1,1,1.2))
annotate_figure(prodLine, 
                left = text_grob("Log Productivity", rot = 90))
prodBox <- ggarrange(plotList[[1]][[2]], plotList[[2]][[2]],
          plotList[[3]][[2]], plotList[[4]][[2]], 
          ncol = 2, nrow = 2, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1,1,1.2,1.2))
annotate_figure(prodBox, 
                left = text_grob("Log Productivity", rot = 90), 
                bottom = text_grob("Operating Model"))
```

So through time, in a given trial, in a given CU now we do see a difference among productivity operating models. I.e. there is an effect when we incorporate feedback between spawners and recruits. In particular large positive recruitment deviations, which are relatively common in both the reference and low alpha operating models, become very rare with a skewed distribution. We can see this in more detail when we look at trends in recruit abundance.

```{r plot trends in recruitment by brood year, echo = FALSE, warning = FALSE}
recBYList <- lapply(seq_along(dirNames), function(h) { 
  datList <- readRDS(paste(here("outputs/simData"), dirNames[h], arrayNames[3], 
                           sep = "/"))
  prodDat <- datList$recBY %>% 
    melt() %>% 
    rename("yr" = "Var1", "cu" =  "Var2", "trial" = "Var3", "var" = "value") %>% 
    mutate(sig = sigNames[h], om = omNames[h])  
  return(prodDat)
}) 
recBYDat <- do.call(rbind, recBYList) %>% 
  filter(sig == "medSig", !yr < 60) %>% #focus on median sig treatment, sim period
  mutate(om = as.factor(om)) %>% 
  mutate(om = factor(om, levels(om)[c(2,1,3,4)]))

plotRecList <- lapply(seq_along(drawTrials), function(i) { 
  dum <- recBYDat %>% 
    filter(trial == drawTrials[i] , cu == 7) #focus on Chilko data only
  q <- ggplot(dum, aes(x = yr, y = var, colour = om)) +
    labs(x = "Year", y = "", title = drawTrials[i]) +
    geom_line(size = 1) +
    scale_colour_discrete(name = "Operating Model") +
    theme_sleekX(position = "bottom") +
    theme(axis.title.y=element_blank()) +
    facet_wrap(~om, nrow = length(unique(omNames)), ncol = 1)
  p <- ggplot(dum, aes(x = om, y = var, fill = om)) +
    geom_boxplot() +
    labs(x = "Op Model", y = "", title = drawTrials[i]) +
    theme_sleekX(position = "bottom") +
    theme(axis.title.y = element_blank(), axis.title.x = element_blank())
  return(list(q, p))
})

recLine <- ggarrange(plotRecList[[1]][[1]], plotRecList[[2]][[1]],
          plotRecList[[3]][[1]], plotRecList[[4]][[1]], 
          ncol = 4, nrow = 1, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1.1,1,1,1.2))
annotate_figure(recLine, 
                left = text_grob("Rec BY", rot = 90))
recBox <- ggarrange(plotRecList[[1]][[2]], plotRecList[[2]][[2]],
          plotRecList[[3]][[2]], plotRecList[[4]][[2]], 
          ncol = 2, nrow = 2, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1,1,1.2,1.2))
annotate_figure(recBox, 
                left = text_grob("Rec BY", rot = 90), 
                bottom = text_grob("Operating Model"))
```

Again, relatively severe declines in median recruit abundance through time in a given CU due to a reduced likelihood of large positive recruitment deviations.

Could differences in observed synchrony also play a role? I.e. is there some sort of interaction between distributions and covariation that may magnify impacts on abundance? Plot time series of synchrony and box plots of median synchrony, by trial, over the simulation period. 

```{r plot synchrony across trials, echo=FALSE, warning=FALSE}
omNames <- c("ref", "skewN", "skewT", "lowA")
dirNamesTrim <- dirNames[c(2, 5, 8, 11)] # cherry pick only mod sigma trials to speed up calcs
recList <- lapply(seq_along(dirNamesTrim), function(h) { 
  datList <- readRDS(paste(here("outputs/simData"), dirNames[h], arrayNames[3], 
                           sep = "/"))
  recDat <- datList$recBY[ , , drawTrials] #subset to focus only on trials of interest
  synchList1 <- lapply(seq_along(drawTrials), function(i) {
    dum <- recDat[ , , i]
    synchDat <- data.frame(om = omNames[h],
                           trial = drawTrials[i],
                           yr = seq(1, nrow(recDat), by = 1),
                           synch = rollapplyr(dum, width = 12, 
                                         function(x) community.sync(x)$obs, 
                                         fill = NA, by.column = FALSE)
                           )
    return(synchDat)
  })
  synchDat2 <- do.call(rbind, synchList1)
  return(synchDat2)
}) 

synchDatFinal <- do.call(rbind, recList) %>% 
  filter(yr > 59) %>% #drop observation period
  mutate(om = factor(om, levels(om)[c(1,4,2,3)])) 

synchPlotList <- lapply(seq_along(drawTrials), function(j) {
  dum <- synchDatFinal %>% 
    filter(trial == drawTrials[j])
  q <- ggplot(dum, aes(x = yr, y = synch, colour = om)) +
    labs(x = "Year", y = "", title = drawTrials[j]) +
    geom_line(size = 1) +
    scale_colour_discrete(name = "Operating Model") +
    theme_sleekX(position = "bottom") +
    theme(axis.title.y=element_blank()) +
    facet_wrap(~om, nrow = length(unique(omNames)), ncol = 1)
  p <- ggplot(dum, aes(x = om, y = synch, fill = om)) +
    geom_boxplot() +
    labs(x = "Op Model", y = "", title = drawTrials[i]) +
    theme_sleekX(position = "bottom") +
    theme(axis.title.y = element_blank(), axis.title.x = element_blank())
  return(list(q, p))
})

synchLine <- ggarrange(synchPlotList[[1]][[1]], synchPlotList[[2]][[1]],
          synchPlotList[[3]][[1]], synchPlotList[[4]][[1]], 
          ncol = 4, nrow = 1, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1.1,1,1,1.2))
annotate_figure(synchLine, 
                left = text_grob("Synchrony", rot = 90))
synchBox <- ggarrange(synchPlotList[[1]][[2]], synchPlotList[[2]][[2]],
          synchPlotList[[3]][[2]], synchPlotList[[4]][[2]], 
          ncol = 2, nrow = 2, common.legend = TRUE, legend = "right", 
          align = "v", heights = c(1,1,1.2,1.2))
annotate_figure(synchBox, 
                left = text_grob("Synchrony", rot = 90), 
                bottom = text_grob("Operating Model"))
```

In short no. Although lowA seems to typically have lower levels of synchrony through time, skewed distributions do not appear to be more synchronized than reference.

In short, the impacts of skewed distributions on performance metrics are worse than simply reducing mean productivity (via alpha), even though outside of a closed-loop simulation context they result in similar median estimates of recruitment. While I think that these operating models are pessimistic relative to a reference scenario, I do not believe they are unrealistic. Multiple studies have identified persistent negative trends in recruitment residuals for large aggregates of Pacific salmon stocks along the coast (sockeye Grant et al. 2018 SOPO and Freshwater et al. 2017 CJFAS; pink/chum Malick et al. 2016 PlosOne; chinook Dorner et al. 2018). In other words, when we see large returns now they are generally associated with large returns in the parental generation, rather than abnormally good survival. I would argue that these trends, plus Sean's papers, warrant including skewed distributions as an alternative to simply shifting average productivity down.