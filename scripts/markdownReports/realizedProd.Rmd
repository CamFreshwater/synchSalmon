---
title: "Realized Productivity Among OMs"
author: "Cam Freshwater"
date: "1/9/2019"
output: html_document
---

```{r readLibraries, message=FALSE, warning=FALSE, include=FALSE}
listOfPackages <- c("plyr", "here", "parallel", "doParallel", "foreach", 
                    "reshape2", "tidyverse", "gsl", "tictoc", "stringr", 
                    "synchrony", "zoo", "Rcpp", "RcppArmadillo", "sn", 
                    "sensitivity", "mvtnorm", "forcats", "ggpubr", "viridis", 
                    "samSim")

here <- here::here

newPackages <- listOfPackages[!(listOfPackages %in% 
                                  installed.packages()[ , "Package"])]
if(length(newPackages)) install.packages(newPackages)
lapply(listOfPackages, require, character.only = TRUE)
```

Carrie wants to make sure that the skewed (and perhaps reference) productivity operating models accurately reflect recent low levels of R/S. Ideally this would  be done by fitting kalman filter stock-recruit models to data generated from skewed OMs and making sure that alpha values are similar. As a first pass however, simply compare average R/S during sim period for each CU to observed.

```{r importAndCleanData, warning=FALSE, include=FALSE}
simPar <- read.csv(here("data/sox/fraserOMInputs_varyCorr.csv"), 
                   stringsAsFactors = F)
#focus only on medium sigma treatments
simParTrim <- subset(simPar,
                     scenario == "medSig" | scenario == "medSigSkew" | 
                       scenario == "medSigSkewT")

scenNames <- unique(simParTrim$scenario)
dirNames <- sapply(scenNames, function(x) paste(x, unique(simParTrim$species),
                                                sep = "_"))

arrayNames <- sapply(dirNames, function(x) {
  list.files(paste(here("outputs/simData"), x, sep="/"), 
             pattern = "\\Arrays.RData$")
})
clusterEvalQ(cl, c(library(here), library(synchrony), library(zoo),
                   library(parallel), library(doParallel), library(foreach),
                   library(samSim)))
bigCUList <- lapply(seq_along(dirNames), function (h) {
  listSynchLists <- lapply(1:length(arrayNames[, h]), function (x) {
    datList <- readRDS(paste(here("outputs/simData"), dirNames[h],
                             arrayNames[x, h], sep = "/"))
  }) #iterate across different OMs within a scenario
  plotList[[h]] <- listSynchLists
}) #iterate across different scenarios
names(bigCUList) <- dirNames

```

```{r plotData, warning=FALSE, include=FALSE}
omNames <- c("ref", "skew", "skewT")
nPrime <- bigCUList[[1]][[1]]$nPrime
plotDat <- NULL
for (i in seq_along(dirNames)) {
  dum <- bigCUList[[i]][[2]]$logRS %>% 
    melt() %>% 
    dplyr::rename("yr" = "Var1", "cu" =  "Var2", "trial" = "Var3", 
                  "logRS" = "value") %>% 
    group_by(cu, yr) %>% 
    summarise(meanLogRS = mean(logRS)) %>% 
    #use means AMONG TRIALS (i.e. violin plots show interannual variability)
    mutate(om = as.factor(ifelse(yr > nPrime, omNames[i], "obs"))) %>% 
    #remove all years from priming period except last 2 generations
    filter(yr > (nPrime - 7))
  plotDat <- rbind(plotDat, dum)
}  

ggplot(plotDat, aes(x = om, y = meanLogRS)) +
  geom_violin(draw_quantiles = c(0.5), 
              position = position_dodge(width = 0.75)) +
  labs(y = "Realized Productivity",
       x = "Operating Model") +
  theme_sleekX(facetSize = 1.2, axisSize = 16, legendSize = 0.85) +
  facet_wrap(~cu, scales = "free_y")

```

Variability in productivity in recent years makes it difficult to interpret. Will need to directly compare simulated R/S from alpha values equivalent to Sue's Kalman filter estimates and see how they compare rather than using observed alone. 

##Update January 12##
Carrie supplied alphas estimated using a Kalman filter for 11 Fraser CUs (all Ricker type stocks). Added these to a new fraserCUPars.csv which can be run by samSim without ricPars/larkPars to forward simulate dynamics if productivity remains depressed.

Note that to avoid issues with overlap constraints (requires all MUs to be present), the MP is a fixed ER rather than TAM. This will obviously impact the long-term outcomes but shouldn't influence the comparison between different productivity OMs.

```{r importSimRunData, warning=FALSE, include=FALSE}
simPar <- read.csv(here("data/sox/fraserOMInputs_kalmanA.csv"), 
                   stringsAsFactors = F)
cuPar <- read.csv(here("data/sox/fraserCUpars_lowKalmanA.csv"), 
                  stringsAsFactors = F)
srDat <- read.csv(here("data/sox/fraserRecDatTrim.csv"), stringsAsFactors = F)
catchDat <- read.csv(here("data/sox/fraserCatchDatTrim.csv"), 
                     stringsAsFactors = F)
tamFRP <- read.csv(here("data/sox/tamRefPts.csv"), stringsAsFactors = F)
ricPars <- read.csv(here("data/sox/pooledRickerMCMCPars.csv"), 
                    stringsAsFactors = F)
larkPars <- read.csv(here("data/sox/pooledLarkinMCMCPars.csv"), 
                     stringsAsFactors = F)

scenNames <- unique(simPar$scenario)
dirNames <- sapply(scenNames, function(x) paste(x, unique(simPar$species),
                                                sep = "_"))

for(i in seq_along(dirNames)) {
  d <- subset(simPar, scenario == scenNames[i])
  if (d$nameOM == "lowKalmanA") {
    # separate out lowKalmaA scenario so that specific alpha values are passed 
    # rather than sampling from posterior distributions
    recoverySim(d, cuPar, catchDat = catchDat, srDat = srDat, 
                variableCU = FALSE, ricPars = NULL, larkPars = NULL, 
                tamFRP = tamFRP, dirName=dirNames[i], nTrials = 5,
                multipleMPs = TRUE)
  } else {
    recoverySim(d, cuPar, catchDat = catchDat, srDat = srDat, 
                variableCU = FALSE, ricPars = ricPars, larkPars = larkPars, 
                tamFRP = tamFRP, dirName=dirNames[i], nTrials = 5,
                multipleMPs = TRUE)
  }
}
```

